{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4k9TPJWt4Hpj",
        "outputId": "26ecb5af-86ca-457a-b02c-3cbafaad06a7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "os.path.exists('/content/drive/MyDrive/Capstone_GE_DSI_CV_Project/preprocessed_data/CT_lung_cancer/PETCT_2dac5ef654_axial_277.jpg')"
      ],
      "metadata": {
        "id": "ubEWXfQQwjlu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cdedb8b9-1d3b-47e4-9c9c-334d05e4903e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "False"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pydicom\n",
        "!pip install opencv-python\n",
        "!pip install pillow # optional\n",
        "!pip install pandas\n",
        "!pip3 install numpy\n",
        "!pip3 install dicom2nifti\n",
        "!pip3 install nibabel\n",
        "!pip3 install pydicom\n",
        "!pip3 install tqdm\n",
        "!pip3 install nilearn\n",
        "!pip install --quiet torchio==0.18.90"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "flbIWn8j4NpC",
        "outputId": "1fd83cd5-954b-4876-e76a-dc1694eab357"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pydicom\n",
            "  Downloading pydicom-2.4.3-py3-none-any.whl (1.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m13.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pydicom\n",
            "Successfully installed pydicom-2.4.3\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.10/dist-packages (4.8.0.76)\n",
            "Requirement already satisfied: numpy>=1.21.2 in /usr/local/lib/python3.10/dist-packages (from opencv-python) (1.23.5)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.10/dist-packages (9.4.0)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (1.5.3)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2023.3.post1)\n",
            "Requirement already satisfied: numpy>=1.21.0 in /usr/local/lib/python3.10/dist-packages (from pandas) (1.23.5)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas) (1.16.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (1.23.5)\n",
            "Collecting dicom2nifti\n",
            "  Downloading dicom2nifti-2.4.9-py3-none-any.whl (43 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.7/43.7 kB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: nibabel in /usr/local/lib/python3.10/dist-packages (from dicom2nifti) (4.0.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from dicom2nifti) (1.23.5)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from dicom2nifti) (1.11.3)\n",
            "Requirement already satisfied: pydicom>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from dicom2nifti) (2.4.3)\n",
            "Collecting python-gdcm (from dicom2nifti)\n",
            "  Downloading python_gdcm-3.0.22-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (13.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.0/13.0 MB\u001b[0m \u001b[31m39.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: packaging>=17.0 in /usr/local/lib/python3.10/dist-packages (from nibabel->dicom2nifti) (23.2)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from nibabel->dicom2nifti) (67.7.2)\n",
            "Installing collected packages: python-gdcm, dicom2nifti\n",
            "Successfully installed dicom2nifti-2.4.9 python-gdcm-3.0.22\n",
            "Requirement already satisfied: nibabel in /usr/local/lib/python3.10/dist-packages (4.0.2)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from nibabel) (1.23.5)\n",
            "Requirement already satisfied: packaging>=17.0 in /usr/local/lib/python3.10/dist-packages (from nibabel) (23.2)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from nibabel) (67.7.2)\n",
            "Requirement already satisfied: pydicom in /usr/local/lib/python3.10/dist-packages (2.4.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (4.66.1)\n",
            "Collecting nilearn\n",
            "  Downloading nilearn-0.10.2-py3-none-any.whl (10.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.4/10.4 MB\u001b[0m \u001b[31m34.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: joblib>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from nilearn) (1.3.2)\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.10/dist-packages (from nilearn) (4.9.3)\n",
            "Requirement already satisfied: nibabel>=3.2.0 in /usr/local/lib/python3.10/dist-packages (from nilearn) (4.0.2)\n",
            "Requirement already satisfied: numpy>=1.19.0 in /usr/local/lib/python3.10/dist-packages (from nilearn) (1.23.5)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from nilearn) (23.2)\n",
            "Requirement already satisfied: pandas>=1.1.5 in /usr/local/lib/python3.10/dist-packages (from nilearn) (1.5.3)\n",
            "Requirement already satisfied: requests>=2.25.0 in /usr/local/lib/python3.10/dist-packages (from nilearn) (2.31.0)\n",
            "Requirement already satisfied: scikit-learn>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from nilearn) (1.2.2)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from nilearn) (1.11.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from nibabel>=3.2.0->nilearn) (67.7.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.1.5->nilearn) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.1.5->nilearn) (2023.3.post1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.25.0->nilearn) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.25.0->nilearn) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.25.0->nilearn) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.25.0->nilearn) (2023.7.22)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=1.0.0->nilearn) (3.2.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas>=1.1.5->nilearn) (1.16.0)\n",
            "Installing collected packages: nilearn\n",
            "Successfully installed nilearn-0.10.2\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m172.7/172.7 kB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m52.7/52.7 MB\u001b[0m \u001b[31m9.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pathlib as plb\n",
        "import tempfile\n",
        "import os\n",
        "import dicom2nifti\n",
        "import nibabel as nib\n",
        "import numpy as np\n",
        "import pydicom\n",
        "import sys\n",
        "import shutil\n",
        "import nilearn.image\n",
        "from tqdm import tqdm\n",
        "\n",
        "import enum\n",
        "import time\n",
        "import random\n",
        "import multiprocessing\n",
        "from pathlib import Path\n",
        "\n",
        "import torch\n",
        "import torchvision\n",
        "import torchio as tio\n",
        "import torch.nn.functional as F\n",
        "import torchvision.transforms as T\n",
        "from torchvision.utils import save_image\n",
        "\n",
        "import numpy as np\n",
        "# from unet import UNet\n",
        "import pandas as pd\n",
        "from scipy import stats\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from IPython import display\n",
        "from tqdm.auto import tqdm\n",
        "from pathlib import Path\n",
        "\n",
        "from PIL import Image\n",
        "\n",
        "from skimage.measure import regionprops_table"
      ],
      "metadata": {
        "id": "7JPWNgDr4QjW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_num_samples = 5000\n",
        "val_num_samples = 2000\n",
        "test_num_samples = 1000"
      ],
      "metadata": {
        "id": "mI21JILjCxPs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_randomized_subset(arr, num_samples, seed):\n",
        "  np.random.seed(seed)\n",
        "  neg_slices_index = np.random.choice(len(arr), num_samples, replace=False)\n",
        "  neg_file_names = np.array(arr)[neg_slices_index]\n",
        "\n",
        "  return neg_file_names"
      ],
      "metadata": {
        "id": "tNYZc6fWC_Xe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "path = '/content/drive/MyDrive/Capstone_GE_DSI_CV_Project/preprocessed_data/negative/data'\n",
        "all_neg_files = os.listdir(path)\n",
        "print(len(all_neg_files))"
      ],
      "metadata": {
        "id": "1gYg45wz4Wcc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "outputId": "776fe8fb-a12d-4c4c-d0b7-55ec5f56328c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-7-04b83ac9d1f0>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mpath\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'/content/drive/MyDrive/Capstone_GE_DSI_CV_Project/preprocessed_data/negative/data'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mall_neg_files\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall_neg_files\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/drive/MyDrive/Capstone_GE_DSI_CV_Project/preprocessed_data/negative/data'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from numpy.random import default_rng\n",
        "import random\n",
        "\n",
        "num_samples = train_num_samples + val_num_samples + test_num_samples\n",
        "seed = 10\n",
        "\n",
        "neg_file_names = get_randomized_subset(all_neg_files, num_samples, seed)"
      ],
      "metadata": {
        "id": "Ehi_xerh7JNa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cancer_samples = pd.read_csv('/content/drive/MyDrive/Capstone_GE_DSI_CV_Project/preprocessed_data/CT_labels.csv')\n",
        "lung_cancer_df, lymphoma_df, melanoma_df = cancer_samples[cancer_samples.cancer_type=='lung_cancer'], cancer_samples[cancer_samples.cancer_type=='lymphoma'], cancer_samples[cancer_samples.cancer_type=='melanoma']\n",
        "\n",
        "print(len(lung_cancer_df), len(lymphoma_df), len(melanoma_df))"
      ],
      "metadata": {
        "id": "Sj_hYVfX-FDw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# LUNG CANCER\n",
        "all_lung_files = lung_cancer_df.img_filename.tolist()\n",
        "num_samples = train_num_samples + val_num_samples + test_num_samples\n",
        "seed = 50\n",
        "\n",
        "lung_cancer_file_names = get_randomized_subset(all_lung_files, num_samples, seed)"
      ],
      "metadata": {
        "id": "hGGgq6yi_zVK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# LYMPHOMA\n",
        "all_lymphoma_files = lymphoma_df.img_filename.tolist()\n",
        "num_samples = train_num_samples + val_num_samples + test_num_samples\n",
        "seed = 320\n",
        "\n",
        "lymphoma_file_names = get_randomized_subset(all_lymphoma_files, num_samples, seed)"
      ],
      "metadata": {
        "id": "8kE_5UgPBwSb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# MELANOMA\n",
        "all_melanoma_files = melanoma_df.img_filename.tolist()\n",
        "num_samples = train_num_samples + val_num_samples + test_num_samples\n",
        "seed = 921\n",
        "\n",
        "melanoma_file_names = get_randomized_subset(all_melanoma_files, num_samples, seed)"
      ],
      "metadata": {
        "id": "qAWUbMWmB-Ze"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_val_test_split(arr, seed):\n",
        "\n",
        "  split1 = int(train_num_samples/num_samples * len(arr))\n",
        "  split2 = int((train_num_samples+val_num_samples)/num_samples * len(arr))\n",
        "\n",
        "  np.random.seed(seed)\n",
        "  np.random.shuffle(arr)\n",
        "  train = arr[:split1]\n",
        "  val = arr[split1:split2]\n",
        "  test = arr[split2:]\n",
        "  return train, val, test"
      ],
      "metadata": {
        "id": "b5ltZlfyCDTs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "seed = 10\n",
        "lung_train, lung_val, lung_test = train_val_test_split(lung_cancer_file_names, seed)"
      ],
      "metadata": {
        "id": "t6g82VjZE_Q1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "seed = 10\n",
        "lymphoma_train, lymphoma_val, lymphoma_test = train_val_test_split(lymphoma_file_names, seed)"
      ],
      "metadata": {
        "id": "EzZMUEIPF_PC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "seed = 10\n",
        "melanoma_train, melanoma_val, melanoma_test = train_val_test_split(melanoma_file_names, seed)"
      ],
      "metadata": {
        "id": "wgACvHJVF__E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "seed = 10\n",
        "negative_train, negative_val, negative_test = train_val_test_split(neg_file_names, seed)"
      ],
      "metadata": {
        "id": "FhtXGM7m81OM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lung_train = np.array([lung_train, ['lung_cancer' for i in range(len(lung_train))], ['train' for i in range(len(lung_train))]]).T"
      ],
      "metadata": {
        "id": "c9IX1kEIHLu1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lymphoma_train = np.array([lymphoma_train, ['lymphoma' for i in range(len(lymphoma_train))], ['train' for i in range(len(lymphoma_train))]]).T"
      ],
      "metadata": {
        "id": "HuWb3661IYxf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "melanoma_train = np.array([melanoma_train, ['melanoma' for i in range(len(melanoma_train))], ['train' for i in range(len(melanoma_train))]]).T"
      ],
      "metadata": {
        "id": "enhaFYNGIflz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "negative_train = np.array([negative_train, ['negative' for i in range(len(negative_train))], ['train' for i in range(len(negative_train))]]).T"
      ],
      "metadata": {
        "id": "vVq8R-Up9Q9J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lung_val = np.array([lung_val, ['lung_cancer' for i in range(len(lung_val))], ['val' for i in range(len(lung_val))]]).T"
      ],
      "metadata": {
        "id": "iy1VVaEbIjrz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lung_test = np.array([lung_test, ['lung_cancer' for i in range(len(lung_test))], ['test' for i in range(len(lung_test))]]).T"
      ],
      "metadata": {
        "id": "-0d1YnCPImiw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lymphoma_val = np.array([lymphoma_val, ['lymphoma' for i in range(len(lymphoma_val))], ['val' for i in range(len(lymphoma_val))]]).T"
      ],
      "metadata": {
        "id": "FEeek60DIoIf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lymphoma_test = np.array([lymphoma_test, ['lymphoma' for i in range(len(lymphoma_test))], ['test' for i in range(len(lymphoma_test))]]).T"
      ],
      "metadata": {
        "id": "4XEQmI9CIrEv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "melanoma_val = np.array([melanoma_val, ['melanoma' for i in range(len(melanoma_val))], ['val' for i in range(len(melanoma_val))]]).T"
      ],
      "metadata": {
        "id": "VgnKdsFTItcf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "melanoma_test = np.array([melanoma_test, ['melanoma' for i in range(len(melanoma_test))], ['test' for i in range(len(melanoma_test))]]).T"
      ],
      "metadata": {
        "id": "iGVNiVG8IwF_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "negative_val = np.array([negative_val, ['negative' for i in range(len(negative_val))], ['val' for i in range(len(negative_val))]]).T"
      ],
      "metadata": {
        "id": "fc8IvUla9Ubw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "negative_test = np.array([negative_test, ['negative' for i in range(len(negative_test))], ['test' for i in range(len(negative_test))]]).T"
      ],
      "metadata": {
        "id": "Rl3mpg-x9W0b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "full_master_list = np.concatenate((lung_train, lung_val, lung_test, lymphoma_train, lymphoma_val, lymphoma_test, melanoma_train, melanoma_val, melanoma_test, negative_train, negative_val, negative_test))"
      ],
      "metadata": {
        "id": "ZBWHSo21Ix7v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "full_master_list_df = pd.DataFrame(full_master_list, columns = ['file_name','cancer_type','split'])\n",
        "full_master_list_df"
      ],
      "metadata": {
        "id": "N0YFINV8JBXj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(full_master_list_df[full_master_list_df['split']=='train']), len(full_master_list_df[full_master_list_df['split']=='val']), len(full_master_list_df[full_master_list_df['split']=='test']))"
      ],
      "metadata": {
        "id": "a7eQ_PVdO2kS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "full_master_list_df.to_csv('/content/drive/MyDrive/Capstone_GE_DSI_CV_Project/preprocessed_data/train_test_split_master.csv', index=False)"
      ],
      "metadata": {
        "id": "PpAE75oYJXWR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = full_master_list_df[full_master_list_df[\"file_name\"].duplicated()]\n",
        "df"
      ],
      "metadata": {
        "id": "RRKDMYFgAnHy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for f in df.file_name.unique():\n",
        "  for i in ['train','test','val']:\n",
        "    folder = f'/content/drive/MyDrive/Capstone_GE_DSI_CV_Project/preprocessed_data/CT_DETR/{i}'\n",
        "    if os.path.exists(folder+f'/{f}'):\n",
        "      os.remove(folder+f'/{f}')\n",
        "\n",
        "    folder = f'/content/drive/MyDrive/Capstone_GE_DSI_CV_Project/preprocessed_data/SUV_DETR/{i}'\n",
        "    if os.path.exists(folder+f'/{f}'):\n",
        "      os.remove(folder+f'/{f}')"
      ],
      "metadata": {
        "id": "ekvHFHrLBWJZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "full_master_list_v2 = full_master_list_df[~full_master_list_df.file_name.isin(df.file_name.unique())]"
      ],
      "metadata": {
        "id": "hvP_EHoHDEzl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "full_master_list_v2.to_csv('/content/drive/MyDrive/Capstone_GE_DSI_CV_Project/preprocessed_data/train_test_split_master_v2.csv', index=False)"
      ],
      "metadata": {
        "id": "X_sMp2ysEOOH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.file_name.unique()"
      ],
      "metadata": {
        "id": "_angQUbAFEn1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "file = open('/content/drive/MyDrive/Capstone_GE_DSI_CV_Project/preprocessed_data/leaked.txt','w')\n",
        "\n",
        "for item in df.file_name.unique():\n",
        "  file.write('gs://petct_preprocessed_data/SUV_DETR/'+item+\"\\n\")\n",
        "  file.write('gs://petct_preprocessed_data/CT_DETR/'+item+\"\\n\")\n",
        "file.close()"
      ],
      "metadata": {
        "id": "7fgoBQmNFhSB"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}